# @package _global_

mode_eval: 'amortize_encdec'
base_model: 'gpt2-large'

pretrained_model_amort: 't5-base'
question_model_amort: null
tokenizer_name_amort: 't5-base'

token_dim: null
num_virtual_tokens: 24

inner_lr: 0.3
num_inner_steps: 1
lift_ratio: 1.0

qencoder_type: 'encdec'
normalize: False

pretrain_summarization: False
pretrain_summarization_model: t5-base


num_cross_attention_blocks: 4
sample_weights: True
sample_steps: ${val_steps}
null_shift: False
nul_shift_lam: null

hierarchy_aware: False
hierarchy_aware_p: 0.0
qencoder_init: False

seed: 42
context_window_list: [16, 32]
c_prompt_cls: 0.
c_context_opt: 0.

bidirectional_decoder: False

bm_learned_layers: -1
batch_size: 16
generation_batch_size: 1
grad_acc_steps: 1

layer_num_virtual_tokens: 2
dropout_p: 0.0
neftune: False
noise_alpha: 5.
no_aggregate: False

lt_lr: 2.5e-5
lt_epochs: 0
lt_steps: 1000000
lt_val_steps: 16
lt_batch_size: -1
lt_grad_acc_steps: -1
lt_stopping_metric: 'max_f1'
lt_patience: 3
topk_mix: 0

log_stepwise_metrics: False

use_pretrained: False
base_model_state_dict_path: null

# LoRA
encdec_lora: False
qenc_lora: False
lora_rank: 32
lora_alpha: 16
lora_dropout: 0.05

optimizer: 'adam'
eval: [em] #a list containing em, emK for integer K for top K evaluation, or 'ppl' to compute average answer token ppl/nll
num_beams: 12
num_beam_groups: 4
diversity_penalty: 10.0

hydra:
  run:
    dir: .